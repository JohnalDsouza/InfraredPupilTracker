{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6073ef19-9670-4608-940a-52eed62b130c",
   "metadata": {},
   "source": [
    "\n",
    "# DETECTION OF PUPIL         \n",
    "   * Johnal Dsouza\n",
    "   * Abdullah Abdullah\n",
    "_______________________\n",
    "\n",
    "The pupil of the eye is detected using OpenCV and Python.\n",
    "Various morphological operation such as Color-Conversion, Contrast-Enhancement, \n",
    "Blurring, Canny-Edge-Detection and Morphological-Closing.\n",
    "_______________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd26f14-175d-4d99-8d06-db2b2b47b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random as rng\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "frame_rate = []\n",
    "time_rate = []\n",
    "video_path = 'output2jd.mp4'  # Replace with your video file path\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "Total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "center_list = {} \n",
    "frame_no =1\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    ###################################\n",
    "    ##### PREPROCESSING OF IMAGE ######\n",
    "    ###################################\n",
    "    \n",
    "    roi = frame[0:350, 0:500]\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    # Enhances the contrast of an image\n",
    "    cl1 = cv2.createCLAHE(clipLimit=8, tileGridSize=(8, 8))\n",
    "    clahe = cl1.apply(gray)\n",
    "    # Blurring of image\n",
    "    blur = cv2.medianBlur(clahe,17)\n",
    "    blurred = cv2.GaussianBlur(blur, (21, 21), 1.5, 1.5, cv2.BORDER_REPLICATE)\n",
    "    # Detect edges\n",
    "    edges = cv2.Canny(blurred, threshold1=55, threshold2=100)\n",
    "    # Perform Morphological Closing \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10,10))\n",
    "    output = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    # Find Contours\n",
    "    _contours, _ = cv2.findContours(output, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    _drawing = np.copy(roi)\n",
    "    \n",
    "    _contours_filtered = []\n",
    "    \n",
    "    ###########################################\n",
    "    ####### FINDING CIRCULAR CONTOURS #########\n",
    "    ###########################################\n",
    "    \n",
    "    for contour_index, contour in enumerate(_contours):\n",
    "        convex_hull = cv2.convexHull(contour)\n",
    "        area_hull = cv2.contourArea(convex_hull)\n",
    "        if area_hull>280:\n",
    "            # print(area_hull)\n",
    "            circumference_hull = cv2.arcLength(convex_hull, True)\n",
    "            \n",
    "            if circumference_hull <= 300:\n",
    "                circularity_hull = (4 * np.pi * area_hull) / circumference_hull ** 2\n",
    "                if  circularity_hull > 0.85:\n",
    "                    # print(circularity_hull)\n",
    "                    _contours_filtered.append(convex_hull)\n",
    "    \n",
    "    ###################################################################\n",
    "    ####### SELECTING THE BEST CIRCULAR CONTOUR ie. PUPIL #############\n",
    "    ###################################################################\n",
    "    \n",
    "    min_circularity = 1.5  \n",
    "    min_circularity_circle = None\n",
    "    \n",
    "    minEllipse = [cv2.fitEllipse(c) for c in _contours_filtered]\n",
    "    \n",
    "    for i, ellipse in enumerate(minEllipse):\n",
    "        circumference = cv2.arcLength(_contours_filtered[i], True)\n",
    "        circularity = circumference ** 2 / (4 * math.pi * cv2.contourArea(_contours_filtered[i]))\n",
    "\n",
    "        if circularity < min_circularity:\n",
    "            min_circularity = circularity\n",
    "            min_circularity_circle = ellipse\n",
    "            \n",
    "    ################################      \n",
    "    ###### DRAWING THE PUPIL  ###### \n",
    "    ################################ \n",
    "    \n",
    "    if min_circularity_circle is not None:\n",
    "        contour_points = cv2.ellipse2Poly((int(min_circularity_circle[0][0]), int(min_circularity_circle[0][1])),\n",
    "                                          (int(min_circularity_circle[1][0] / 2), int(min_circularity_circle[1][1] / 2)),\n",
    "                                          int(min_circularity_circle[2]), 0, 360, 1)\n",
    "        m = cv2.moments(contour_points)\n",
    "        if m['m00'] != 0:\n",
    "            center = (int(m['m10'] / m['m00']), int(m['m01'] / m['m00']))\n",
    "            # The center of the pupil is stored in center_list, which will be used for Analysis\n",
    "            center_list.update({frame_no: center})\n",
    "            cv2.circle(_drawing, center, 3, (0, 255, 0), -1)   \n",
    "        try:\n",
    "            cv2.ellipse(_drawing, box=min_circularity_circle, color=(0, 255, 0),thickness = 2)   \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    \n",
    "    # Find frame-per-second\n",
    "    time_rate.append((end-start).total_seconds())\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    frame_rate.append(1 / (end - start).total_seconds())\n",
    "    cv2.putText(_drawing, fps, (0, 300),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    \n",
    "    out.write(_drawing)\n",
    "    # Display Output\n",
    "    cv2.imshow('gray2', blurred)\n",
    "    cv2.imshow('edges', edges)\n",
    "    cv2.imshow('circles', _drawing)\n",
    "    \n",
    "    frame_no += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfc15318-a870-40c1-a631-bc9c8e79b866",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009141012025316442\n"
     ]
    }
   ],
   "source": [
    "avg = sum(time_rate)/len(time_rate)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2030c994-5ba5-4570-8384-a01b79a716b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.09097396054878\n"
     ]
    }
   ],
   "source": [
    "avg = sum(frame_rate) / len(frame_rate)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653399b5-b9dd-4826-ba58-c8cc05c73e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265\n"
     ]
    }
   ],
   "source": [
    "print(len(center_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3ac73-f962-4a0c-97af-dc4b85914e22",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "# ANNOTATION OF DATASET\n",
    "The video data is annotated of each frame, with a rectangular box is drawn for each frame.\n",
    "The top left (x,y) position and the bottom right (x,y) position of the rectangle is saved along with its frame no.\n",
    "in a text file.\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ec5116-2c9e-4103-ae34-e5e8f125923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangles data saved to rectangles_data.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Global variables\n",
    "current_frame = None\n",
    "rectangle_points = []\n",
    "rectangles_data = []\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global rectangle_points\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        rectangle_points = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        rectangle_points.append((x, y))\n",
    "        rectangles_data.append(rectangle_points)\n",
    "        cv2.rectangle(current_frame, rectangle_points[0], rectangle_points[1], (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Video\", current_frame)\n",
    "\n",
    "\n",
    "def process_frame(frame, frame_number):\n",
    "    global current_frame\n",
    "\n",
    "    # Create a copy of the frame\n",
    "    current_frame = frame.copy()\n",
    "\n",
    "    # Display the frame number on the screen\n",
    "    cv2.putText(current_frame, f\"Frame: {frame_number}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Video\", current_frame)\n",
    "\n",
    "    # Set the mouse callback function\n",
    "    cv2.setMouseCallback(\"Video\", draw_rectangle)\n",
    "\n",
    "    # Wait for key press\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # Check if 'q' is pressed to quit\n",
    "    if key == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"output3aa.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video file opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "frame_number = 0\n",
    "while cap.isOpened():\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Increment the frame number\n",
    "    frame_number += 1\n",
    "\n",
    "    # Check if frame is read successfully\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame\n",
    "    result = process_frame(frame, frame_number)\n",
    "\n",
    "    # Check if processing is stopped\n",
    "    if not result:\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the rectangle data to a file\n",
    "output_file = \"rectangles_data.txt\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for i,rect in enumerate(rectangles_data):\n",
    "        file.write(f\"{i+1}:({rect[0][0]},{rect[0][1]});({rect[1][0]},{rect[1][1]})\\n\")\n",
    "\n",
    "print(f\"Rectangles data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a19727-9e9b-482a-9c3c-427741cda272",
   "metadata": {},
   "source": [
    "#### Converting Text data into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "00e388ed-d7de-47d4-b773-e195f30a678d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = \"rectangles_data.txt\"\n",
    "##### CONVERTING ANNOTATED DATA IN DICTIONARY\n",
    "rectangles_dict = {}\n",
    "with open(data_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line into frame number and coordinates\n",
    "        frame_num, *coord_str = line.strip().split(\":\")\n",
    "        \n",
    "        # Convert frame number to integer\n",
    "        frame_num = int(frame_num)\n",
    "        \n",
    "        coordinates = []\n",
    "        for coord in coord_str:\n",
    "            # print(coord)\n",
    "            x1y1,x2y2 = coord.split(\";\")\n",
    "            # split coordinates into its individual components\n",
    "            x1,y1 = x1y1.strip(\"()\").split(\",\")\n",
    "            x2,y2 = x2y2.strip(\"()\").split(\",\")\n",
    "            \n",
    "        rectangles_dict[frame_num] = [(int(x1), int(y1)) , (int(x2),int(y2))]\n",
    "\n",
    "# Print the dictionary\n",
    "print(rectangles_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422d85b-e475-48b9-bd12-613b9b30de94",
   "metadata": {},
   "source": [
    "--------------------- \n",
    "# PUPIL DETECTION ANALYSIS\n",
    "The pupil center is checked if it lies in between the bounding rectangle.\n",
    "if Yes, number 1 is appended to detection, else 0\n",
    "Further calculation of Accuracy, Precision, Recall and F1 score is found out\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7de8c-f8bf-48c8-b556-2f876074db77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detection = []\n",
    "for key in center_list.keys():\n",
    "    if key in rectangles_dict.keys():\n",
    "        \n",
    "        center_value = center_list[key]\n",
    "        rectangle_values = rectangles_dict[key]\n",
    "        x_min, y_min = rectangle_values[0]\n",
    "        x_max, y_max = rectangle_values[1]\n",
    "        \n",
    "        # check if pupil center lies in bounding rectangle\n",
    "        if x_min <= center_value[0] <= x_max and y_min <= center_value[1] <= y_max:\n",
    "            detection.append(1)\n",
    "            print(f\"Key {key}: Center value {center_value} is within the rectangle.\")\n",
    "        else:\n",
    "            detection.append(0)\n",
    "            print(f\"Key {key}: Center value {center_value} is outside the rectangle.\")\n",
    "    else:\n",
    "        print(f\"Key {key} is not present in rectangles_dict.\")\n",
    "print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "34ce1fcb-c5e5-4a36-a7a4-b35937991408",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames = 1412\n",
      "Correctly detected pupil frames = 1250\n",
      "Incorrectly detected pupil frames = 15\n",
      "No detection of pupil in frame = 147\n"
     ]
    }
   ],
   "source": [
    "Total_no_frames = Total_frames\n",
    "Correctly_detect_pupil = detection.count(1) # Correctly detected pupil frames\n",
    "Incorrect_detect_pupil = detection.count(0) # Incorrectly detected pupil frames\n",
    "Missed_detect = Total_no_frames- Correctly_detect_pupil-Incorrect_detect_pupil # No detection of pupil in frames\n",
    "print(f\"Total frames = {Total_no_frames}\")\n",
    "print(f\"Correctly detected pupil frames = {Correctly_detect_pupil}\")\n",
    "print(f\"Incorrectly detected pupil frames = {Incorrect_detect_pupil}\")\n",
    "print(f\"No detection of pupil in frame = {Missed_detect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cf55524e-d7a6-407c-af9b-8540dea5ecc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.53%\n",
      "Incorrect Detection Rate: 1.06%\n",
      "Missed Detection Rate: 10.41%\n",
      "Precision: 98.81%\n",
      "Recall: 89.48%\n",
      "F1 Score: 93.91\n"
     ]
    }
   ],
   "source": [
    "Accuracy = (Correctly_detect_pupil/Total_no_frames)*100\n",
    "Incorrect_detect_rate = (Incorrect_detect_pupil/Total_no_frames)*100\n",
    "Missed_detect_rate = (Missed_detect/Total_no_frames)*100\n",
    "Precision = (Correctly_detect_pupil/(Correctly_detect_pupil+Incorrect_detect_pupil))*100\n",
    "Recall = (Correctly_detect_pupil/(Correctly_detect_pupil+Missed_detect))*100\n",
    "F1_score = 2*(Precision*Recall)/(Precision+Recall)\n",
    "\n",
    "print(f\"Accuracy: {Accuracy:.2f}%\")\n",
    "print(f\"Incorrect Detection Rate: {Incorrect_detect_rate:.2f}%\")\n",
    "print(f\"Missed Detection Rate: {Missed_detect_rate:.2f}%\")\n",
    "print(f\"Precision: {Precision:.2f}%\")\n",
    "print(f\"Recall: {Recall:.2f}%\")\n",
    "print(f\"F1 Score: {F1_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
